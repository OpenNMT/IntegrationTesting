Building source vocabulary...	
Created dictionary of size 23139 (pruned from 23139)	
	
Building target vocabulary...	
Created dictionary of size 16011 (pruned from 16011)	
	
Preparing training data...	
... shuffling sentences	
... sorting sentences by size	
Prepared 5718 sentences (285 ignored due to length == 0 or > 50)	
	
Preparing validation data...	
... shuffling sentences	
... sorting sentences by size	
Prepared 5718 sentences (285 ignored due to length == 0 or > 50)	
	
Saving source vocabulary to 'data/demo.src.dict'...	
Saving target vocabulary to 'data/demo.targ.dict'...	
Saving data to 'data/demo-train.t7'...	
Loading data from data/demo-train.t7...	
 * vocabulary size: source = 23139; target = 16011	
 * additional features: source = 0; target = 0	
 * maximum sequence length: source = 50; target = 51	
 * number of training sentences: 5718	
 * maximum batch size: 64	
Building model...	
Initializing parameters...	
 * number of parameters: 37354511	
Preparing memory optimization...	
 * sharing 63% of output/gradInput tensors memory between clones	
	
Epoch 1 ; Batch 50/115 ; LR 1.0000 ; Throughput 1787/717/1070 total/src/targ tokens/sec ; PPL 152390.60 ; Free mem 2491678720	
Epoch 1 ; Batch 100/115 ; LR 1.0000 ; Throughput 2553/1028/1524 total/src/targ tokens/sec ; PPL 39733.29 ; Free mem 2468741120	
Validation PPL: 2007.0041286477	
Saving checkpoint to demo-model_epoch1_2007.00.t7...	
